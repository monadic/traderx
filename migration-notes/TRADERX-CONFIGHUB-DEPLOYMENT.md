# TraderX Deployment with ConfigHub: A Complete Analysis

**Status**: Design Document
**Target**: FINOS TraderX Sample Trading Application
**Goal**: Deploy TraderX using ConfigHub canonical patterns, replacing kubectl/Tilt with ConfigHub workers

## Executive Summary

TraderX is a FINOS reference application with 8 microservices that demonstrates financial services architecture. Currently deployed via kubectl and Tilt.dev, it serves as an ideal test case for ConfigHub deployment patterns because:

1. **Multi-service complexity** - 8 distinct services requiring coordination
2. **Polyglot architecture** - Java, Node.js, Python, .NET showcase ConfigHub's language-agnostic approach
3. **Educational purpose** - Already designed for learning, perfect for demonstrating ConfigHub patterns
4. **Real-world representative** - Mirrors actual fintech microservices architecture

This document outlines a complete ConfigHub-native deployment strategy that:
- Replaces kubectl with `cub unit apply`
- Replaces Tilt with ConfigHub workers
- Follows all 12 canonical patterns from global-app
- Provides foundation for DevOps as Apps integration

---

## Part 1: Current State Analysis

### TraderX Architecture (8 Services)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend Layer                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  â”‚ Web GUI         â”‚ (Angular/React)                   â”‚
â”‚  â”‚ Port: 18080     â”‚                                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Business Logic Layer                                    â”‚
â”‚           â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Trade Service   â”‚  â”‚Position Svc  â”‚  â”‚Account Svc â”‚ â”‚
â”‚  â”‚ Port: 18092     â”‚  â”‚Port: 18090   â”‚  â”‚Port: 18091 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚Trade Processor  â”‚  â”‚People Serviceâ”‚  â”‚Trade Feed  â”‚ â”‚
â”‚  â”‚ Port: N/A       â”‚  â”‚Port: 18089   â”‚  â”‚Port: 18088 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Layer                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚Reference Data   â”‚                                    â”‚
â”‚  â”‚Port: 18085      â”‚                                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Current Deployment Methods

**Method 1: kubectl (Traditional)**
```bash
kubectl apply -f kubernetes/
```
Problems:
- No versioning or rollback
- No environment promotion
- Manual coordination across 8 services
- No audit trail

**Method 2: Tilt.dev (Development)**
```python
# Tiltfile
docker_build('trade-service', './trade-service')
k8s_yaml('kubernetes/trade-service.yaml')
```
Benefits (that we need to preserve):
- Fast rebuild on code change
- Live updates to running containers
- Unified dashboard for all services
- Automatic port forwarding

**Problem**: Tilt is dev-only, doesn't handle staging/prod promotion

### Service Inventory & Dependencies

| Service | Language | Port | Dependencies | Purpose |
|---------|----------|------|--------------|---------|
| reference-data | Java/Spring | 18085 | None | Master data (securities, accounts) |
| people-service | Java/Spring | 18089 | reference-data | User/trader management |
| account-service | Node.js/NestJS | 18091 | reference-data | Account operations |
| position-service | Java/Spring | 18090 | reference-data, account-service | Position tracking |
| trade-service | .NET/C# | 18092 | All above | Trade execution |
| trade-processor | Python | N/A (async) | trade-service | Trade settlement |
| trade-feed | Java/Spring | 18088 | trade-service | Real-time feed |
| web-gui | Angular/React | 18080 | All services | User interface |

**Critical Insight**: Services have a **dependency tree**, not just a flat list. ConfigHub must respect this during deployment.

---

## Part 2: ConfigHub Deployment Design

### Canonical Pattern Application

Following [CANONICAL-PATTERNS-SUMMARY.md](./CANONICAL-PATTERNS-SUMMARY.md):

**Pattern 1: Unique Project Naming**
```bash
# Generate unique prefix for this deployment
prefix=$(cub space new-prefix)
# Returns: "cheerful-tiger" (example)
project="${prefix}-traderx"
# Result: "cheerful-tiger-traderx"
```

**Pattern 2: Space Hierarchy**
```
cheerful-tiger-traderx-base          # Base configurations, no target
  â””â”€â”€ cheerful-tiger-traderx-dev     # Development with kind cluster
      â””â”€â”€ cheerful-tiger-traderx-staging  # Staging
          â””â”€â”€ cheerful-tiger-traderx-prod # Production
```

**Pattern 3: Filter Creation**
```bash
# Create filters for different service types
cub filter create all Unit \
  --where-field "Space.Labels.project = '$project'"

cub filter create frontend Unit \
  --where-field "Labels.layer = 'frontend'"

cub filter create backend Unit \
  --where-field "Labels.layer = 'backend'"

cub filter create data Unit \
  --where-field "Labels.layer = 'data'"
```

### ConfigHub Unit Structure

```
cheerful-tiger-traderx-base/
â”œâ”€â”€ Units (Application Services - 8 units)
â”‚   â”œâ”€â”€ reference-data-service
â”‚   â”‚   Labels: {layer: data, lang: java, order: 1}
â”‚   â”œâ”€â”€ people-service
â”‚   â”‚   Labels: {layer: backend, lang: java, order: 2}
â”‚   â”œâ”€â”€ account-service
â”‚   â”‚   Labels: {layer: backend, lang: nodejs, order: 3}
â”‚   â”œâ”€â”€ position-service
â”‚   â”‚   Labels: {layer: backend, lang: java, order: 4}
â”‚   â”œâ”€â”€ trade-service
â”‚   â”‚   Labels: {layer: backend, lang: dotnet, order: 5}
â”‚   â”œâ”€â”€ trade-processor
â”‚   â”‚   Labels: {layer: backend, lang: python, order: 6}
â”‚   â”œâ”€â”€ trade-feed
â”‚   â”‚   Labels: {layer: backend, lang: java, order: 7}
â”‚   â””â”€â”€ web-gui
â”‚       Labels: {layer: frontend, lang: angular, order: 8}
â”‚
â”œâ”€â”€ Units (Infrastructure - 2 units)
â”‚   â”œâ”€â”€ traderx-namespace
â”‚   â”‚   Labels: {type: infra, order: 0}
â”‚   â””â”€â”€ traderx-ingress
â”‚       Labels: {type: infra, order: 9}
â”‚
â”œâ”€â”€ Filters (Deployment Control)
â”‚   â”œâ”€â”€ ordered-deploy
â”‚   â”‚   Query: "ORDER BY Labels.order ASC"
â”‚   â”œâ”€â”€ backend-services
â”‚   â”‚   Query: "Labels.layer = 'backend'"
â”‚   â””â”€â”€ dependent-services
â”‚       Query: "Labels.order > 1"  # Everything except reference-data
â”‚
â””â”€â”€ Sets (Logical Grouping)
    â”œâ”€â”€ core-services
    â”‚   Members: [reference-data, people-service, account-service]
    â”œâ”€â”€ trading-services
    â”‚   Members: [trade-service, trade-processor, trade-feed]
    â””â”€â”€ ui-services
        Members: [web-gui]
```

### Directory Layout (Following global-app)

```
traderx-confighub/
â”œâ”€â”€ bin/
â”‚   â”œâ”€â”€ install-base           # Create base space with all units
â”‚   â”œâ”€â”€ install-envs           # Create dev/staging/prod hierarchy
â”‚   â”œâ”€â”€ apply-all              # Deploy all services to environment
â”‚   â”œâ”€â”€ promote                # Push-upgrade between environments
â”‚   â”œâ”€â”€ proj                   # Return project name
â”‚   â””â”€â”€ ordered-apply          # Apply services in dependency order
â”‚
â”œâ”€â”€ confighub/
â”‚   â””â”€â”€ base/
â”‚       â”œâ”€â”€ namespace.yaml
â”‚       â”œâ”€â”€ reference-data-deployment.yaml
â”‚       â”œâ”€â”€ reference-data-service.yaml
â”‚       â”œâ”€â”€ people-service-deployment.yaml
â”‚       â”œâ”€â”€ people-service-service.yaml
â”‚       â”œâ”€â”€ account-service-deployment.yaml
â”‚       â”œâ”€â”€ account-service-service.yaml
â”‚       â”œâ”€â”€ position-service-deployment.yaml
â”‚       â”œâ”€â”€ position-service-service.yaml
â”‚       â”œâ”€â”€ trade-service-deployment.yaml
â”‚       â”œâ”€â”€ trade-service-service.yaml
â”‚       â”œâ”€â”€ trade-processor-deployment.yaml
â”‚       â”œâ”€â”€ trade-feed-deployment.yaml
â”‚       â”œâ”€â”€ trade-feed-service.yaml
â”‚       â”œâ”€â”€ web-gui-deployment.yaml
â”‚       â”œâ”€â”€ web-gui-service.yaml
â”‚       â””â”€â”€ ingress.yaml
â”‚
â””â”€â”€ README.md
```

---

## Part 3: ConfigHub Workers Replace Tilt

### What Tilt Provides (That We Must Replace)

1. **Fast rebuild loop** - Detects code changes, rebuilds, redeploys
2. **Log streaming** - Unified logs from all services
3. **Port forwarding** - Automatic local access to services
4. **Health checks** - Shows which services are up/down
5. **Unified dashboard** - Single view of entire system

### ConfigHub Worker Architecture

**Key Insight**: ConfigHub workers provide the same benefits as Tilt, but work across environments (dev/staging/prod), not just local dev.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Developer Workstation                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Code Change                                        â”‚ â”‚
â”‚  â”‚   â†“                                                â”‚ â”‚
â”‚  â”‚ git commit + push                                  â”‚ â”‚
â”‚  â”‚   â†“                                                â”‚ â”‚
â”‚  â”‚ cub unit update web-gui --patch                    â”‚ â”‚
â”‚  â”‚   --data '{"image": "traderx/web-gui:abc123"}'    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ ConfigHub API
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ConfigHub (SaaS)                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Unit: web-gui                                      â”‚ â”‚
â”‚  â”‚   Status: UnappliedChanges                         â”‚ â”‚
â”‚  â”‚   Image: traderx/web-gui:abc123                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Worker polls for changes
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kubernetes Cluster (dev)                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ConfigHub Worker Pod                               â”‚ â”‚
â”‚  â”‚   1. Detects UnappliedChanges                      â”‚ â”‚
â”‚  â”‚   2. Fetches unit data                             â”‚ â”‚
â”‚  â”‚   3. Applies to cluster (kubectl apply)            â”‚ â”‚
â”‚  â”‚   4. Updates unit status (Applied)                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ web-gui Pod                                        â”‚ â”‚
â”‚  â”‚   Image: traderx/web-gui:abc123 (NEW)             â”‚ â”‚
â”‚  â”‚   Status: Running                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Worker Configuration

**1. Install Worker in Each Environment**
```bash
# bin/setup-worker
#!/bin/bash
set -e

PROJECT=$(bin/proj)
ENV=$1  # dev, staging, or prod

echo "Installing ConfigHub worker for $PROJECT-$ENV"

# Create worker configuration
cub worker create ${PROJECT}-${ENV}-worker \
  --space ${PROJECT}-${ENV} \
  --target k8s-cluster \
  --poll-interval 10s \
  --auto-apply true

# Deploy worker to Kubernetes
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: confighub-worker
  namespace: ${PROJECT}-${ENV}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: confighub-worker
  template:
    metadata:
      labels:
        app: confighub-worker
    spec:
      serviceAccountName: confighub-worker
      containers:
      - name: worker
        image: confighub/worker:latest
        env:
        - name: CUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: confighub-creds
              key: token
        - name: CUB_API_URL
          value: "https://hub.confighub.com/api"
        - name: WORKER_ID
          value: "${PROJECT}-${ENV}-worker"
        - name: POLL_INTERVAL
          value: "10s"
EOF

echo "âœ… Worker deployed. Changes to ConfigHub units will auto-apply to cluster."
```

**2. Development Workflow (Replacing Tilt)**

**Before (with Tilt):**
```bash
# Terminal 1
tilt up

# Tilt watches files, rebuilds, redeploys
# Edit code â†’ automatic rebuild â†’ see changes in ~5s
```

**After (with ConfigHub Worker):**
```bash
# One-time setup
bin/setup-worker dev

# Then for each change:
# 1. Edit code
# 2. Build new image (can be automated with CI)
docker build -t traderx/web-gui:abc123 ./web-gui
docker push traderx/web-gui:abc123

# 3. Update ConfigHub unit
cub run set-image-reference \
  --container-name web-gui \
  --image-reference :abc123 \
  --space $(bin/proj)-dev

# Worker auto-applies in ~10 seconds
# Watch status:
watch cub unit get web-gui --space $(bin/proj)-dev
```

**Optimization: Add CI Integration**
```bash
# .github/workflows/dev-deploy.yml
name: Auto-Deploy to Dev
on:
  push:
    branches: [main]
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - name: Build image
      run: docker build -t traderx/web-gui:${{ github.sha }} .
    - name: Push image
      run: docker push traderx/web-gui:${{ github.sha }}
    - name: Update ConfigHub
      run: |
        cub run set-image-reference \
          --container-name web-gui \
          --image-reference :${{ github.sha }} \
          --space cheerful-tiger-traderx-dev
    # Worker picks up change and deploys automatically
```

### Feature Comparison: Tilt vs ConfigHub Workers

| Feature | Tilt | ConfigHub Workers | Winner |
|---------|------|-------------------|--------|
| **Fast rebuild** | âœ… Native | âš ï¸ Requires CI | Tilt (for local dev) |
| **Log streaming** | âœ… Built-in | âš ï¸ Use kubectl logs | Tilt |
| **Port forwarding** | âœ… Automatic | âš ï¸ Manual kubectl | Tilt |
| **Dashboard** | âœ… Web UI | âœ… ConfigHub Web UI | Tie |
| **Multi-environment** | âŒ Dev only | âœ… Dev/staging/prod | Workers |
| **Promotion** | âŒ N/A | âœ… Push-upgrade | Workers |
| **Audit trail** | âŒ None | âœ… Full revision history | Workers |
| **Rollback** | âŒ Git revert | âœ… `cub unit apply --revision=N` | Workers |
| **Team collaboration** | âš ï¸ Local only | âœ… Shared state in ConfigHub | Workers |

**Recommendation**: Use **both**
- **Local dev**: Tilt for fast iteration
- **Dev/staging/prod**: ConfigHub workers for environment promotion

This is similar to how people use `docker-compose` locally but Kubernetes in production.

---

## Part 4: Deployment Sequence & Dependency Management

### Challenge: Service Dependencies

TraderX services must start in order:
1. `reference-data` (no dependencies)
2. `people-service` (needs reference-data)
3. `account-service` (needs reference-data)
4. `position-service` (needs reference-data, account-service)
5. `trade-service` (needs all above)
6. `trade-processor` (needs trade-service)
7. `trade-feed` (needs trade-service)
8. `web-gui` (needs all services)

### Solution: Ordered Apply with Filters

**Pattern: Label-based ordering**
```yaml
# confighub/base/reference-data-deployment.yaml
metadata:
  labels:
    order: "1"
    layer: "data"
    service: "reference-data"

# confighub/base/trade-service-deployment.yaml
metadata:
  labels:
    order: "5"
    layer: "backend"
    service: "trade-service"
    depends-on: "reference-data,people-service,account-service,position-service"
```

**Implementation: bin/ordered-apply**
```bash
#!/bin/bash
set -e

SPACE=$1
if [ -z "$SPACE" ]; then
  echo "Usage: bin/ordered-apply <space>"
  exit 1
fi

echo "Deploying TraderX services to $SPACE in dependency order..."

# Apply in order
for order in {0..9}; do
  echo "â³ Applying order $order..."

  # Get units at this order level
  units=$(cub unit list --space $SPACE --format json | \
    jq -r ".[] | select(.Labels.order == \"$order\") | .Slug")

  if [ -z "$units" ]; then
    continue
  fi

  # Apply each unit
  for unit in $units; do
    echo "  ğŸ“¦ Applying $unit..."
    cub unit apply $unit --space $SPACE

    # Wait for it to be healthy before continuing
    timeout 60s bash -c "
      while true; do
        status=\$(cub unit get-live-state $unit --space $SPACE --format json | jq -r '.Status')
        if [ \"\$status\" = \"Running\" ]; then
          break
        fi
        sleep 2
      done
    "
    echo "  âœ… $unit is running"
  done
done

echo "âœ… All services deployed successfully"
```

**Usage:**
```bash
# Deploy to dev
bin/ordered-apply cheerful-tiger-traderx-dev

# Output:
# â³ Applying order 0...
#   ğŸ“¦ Applying traderx-namespace...
#   âœ… traderx-namespace is running
# â³ Applying order 1...
#   ğŸ“¦ Applying reference-data-service...
#   âœ… reference-data-service is running
# â³ Applying order 2...
#   ğŸ“¦ Applying people-service...
#   âœ… people-service is running
# ...
```

---

## Part 5: DevOps as Apps Integration (Design Only)

### Scenario 1: Drift Detection Across 8 Services

**Problem**: In a multi-service system like TraderX, drift can cascade:
```
reference-data drifts (replicas: 3 â†’ 5)
  â†“ causes
people-service to scale (replicas: 2 â†’ 4)
  â†“ causes
trade-service to scale (replicas: 2 â†’ 6)
  â†“ result
Cost increases by $50/month
```

**Solution: Cross-Service Drift Detector**
```bash
# drift-detector analyzes all TraderX units
cub unit list --space '*traderx*' --where "Labels.service LIKE '%'"

# Detects:
# 1. reference-data: replicas drifted (3 â†’ 5)
# 2. people-service: replicas drifted (2 â†’ 4) [cascade]
# 3. trade-service: replicas drifted (2 â†’ 6) [cascade]

# Generates fix:
# Fix root cause (reference-data), others will stabilize
cub unit update reference-data --patch \
  --space traderx-dev \
  --data '{"spec": {"replicas": 3}}'

# Push-upgrade to downstream environments
cub unit update --patch --upgrade \
  --space traderx-staging \
  --where "Slug = 'reference-data'"
```

**Key Insight**: Drift detector would identify **root cause** vs **cascade effects**

### Scenario 2: Cost Optimization for Multi-Service App

**Analysis:**
```
Service             Replicas  CPU/Memory      Monthly Cost
reference-data      3         500m/512Mi      $25
people-service      2         200m/256Mi      $15
account-service     2         200m/256Mi      $15
position-service    2         500m/512Mi      $25
trade-service       3         1000m/1Gi       $75
trade-processor     1         500m/512Mi      $10
trade-feed          2         500m/512Mi      $25
web-gui             1         200m/256Mi      $8
                                        Total: $198/month
```

**Claude AI Analysis:**
```
ğŸ’¡ Cost Optimizer Recommendations:

1. trade-service is over-provisioned:
   - CPU usage: 30% (1000m allocated, 300m used)
   - Recommendation: Reduce to 500m
   - Savings: $25/month

2. reference-data could use vertical scaling:
   - Current: 3 replicas @ 500m each
   - Better: 2 replicas @ 750m each
   - Same capacity, better cache locality
   - Savings: $8/month

3. Development environment over-scaled:
   - All services at production replica count
   - Dev could run with 50% replicas
   - Savings: $60/month (on dev environment)

Total monthly savings: $93 (47% reduction)
```

**Implementation:**
```bash
# Cost optimizer creates recommendations in ConfigHub
cub unit update trade-service --patch \
  --space traderx-dev \
  --label cost.recommendation=reduce-cpu \
  --label cost.savings=25

# Apply optimizations
cub run set-container-resources \
  --container-name trade-service \
  --cpu 500m \
  --space $(bin/proj)-dev

# Test in dev for 1 week, then promote to staging
bin/promote dev staging
```

### Scenario 3: Cross-App Label Integration

**TraderX services write financial metrics:**
```bash
# Trade service labels
cub unit update trade-service --label \
  trades.daily=1250 \
  trades.peak-hour=450 \
  trades.avg-latency-ms=45

# Cost optimizer reads those labels
trades_per_day=$(cub unit get trade-service --space traderx-prod | jq '.Labels["trades.daily"]')
cost_per_trade=$( echo "scale=4; 75 / $trades_per_day" | bc )
# Result: $0.06 per trade

# Recommendation: "Each trade costs $0.06 in infrastructure"
```

**Combined View:**
```bash
# bin/traderx-insights
cub unit list --space '*traderx*' --where "Labels.layer = 'backend'" --format json | \
  jq -r '.[] | {
    service: .Slug,
    drift: .Labels["drift.detected"],
    cost: .Labels["cost.monthly"],
    trades: .Labels["trades.daily"],
    cost_per_trade: (.Labels["cost.monthly"] / .Labels["trades.daily"])
  }'

# Output:
# {
#   "service": "trade-service",
#   "drift": "false",
#   "cost": "75",
#   "trades": "1250",
#   "cost_per_trade": 0.06
# }
```

### Scenario 4: Pre-Deployment Cost Impact

**Before promoting TraderX v2.0 to production:**
```bash
# cost-impact-monitor analyzes the changeset
cub unit diff trade-service \
  --space traderx-staging \
  --from-space traderx-prod

# Detects:
# - Replica increase: 3 â†’ 5 (+$50/month)
# - Memory increase: 1Gi â†’ 2Gi (+$30/month)
# Total impact: +$80/month

# Claude AI assessment:
âš ï¸  Warning: This change increases costs by 40%

   Reason: New ML-based trade matching algorithm
   requires more memory and replicas.

   Recommendation: Deploy to 1 region first,
   measure performance, then scale if needed.
```

**Workflow:**
```bash
# 1. Update staging with new version
cub run set-image-reference \
  --container-name trade-service \
  --image-reference :v2.0 \
  --space traderx-staging

# 2. Cost impact monitor detects pending change
# 3. Shows warning in dashboard
# 4. Team decides: approve or modify

# 5. If approved, promote to production
bin/promote staging prod
```

---

## Part 6: Implementation Roadmap

### Phase 1: Basic ConfigHub Deployment (Week 1)
**Goal**: Replace kubectl with ConfigHub

- [x] Create traderx-confighub/ directory structure
- [ ] Write bin/install-base script
- [ ] Convert all 8 Kubernetes manifests to ConfigHub units
- [ ] Create filters for service layers
- [ ] Test: Deploy to Kind cluster via `cub unit apply`

**Success Criteria**:
```bash
bin/install-base
bin/apply-all dev
# All 8 services running in Kubernetes via ConfigHub
```

### Phase 2: Environment Hierarchy (Week 2)
**Goal**: Demonstrate push-upgrade across environments

- [ ] Create bin/install-envs script
- [ ] Set up dev â†’ staging â†’ prod spaces
- [ ] Implement bin/promote script
- [ ] Test: Make change in dev, promote to staging

**Success Criteria**:
```bash
# Update image in dev
cub run set-image-reference --container-name web-gui --image-reference :v1.1 --space traderx-dev

# Promote to staging
bin/promote dev staging

# Verify
cub unit get web-gui --space traderx-staging
# Should show image: traderx/web-gui:v1.1
```

### Phase 3: Worker Integration (Week 3)
**Goal**: Replace manual apply with automatic workers

- [ ] Create bin/setup-worker script
- [ ] Deploy worker to dev cluster
- [ ] Configure auto-apply on ConfigHub unit changes
- [ ] Test: Update unit in ConfigHub, worker auto-applies

**Success Criteria**:
```bash
# Update unit
cub unit update web-gui --patch --space traderx-dev --data '{"spec":{"replicas":2}}'

# Wait 10 seconds
sleep 10

# Verify worker applied it
kubectl get deployment web-gui -n traderx-dev
# Should show 2 replicas
```

### Phase 4: DevOps Apps Integration (Week 4)
**Goal**: Demonstrate drift detection and cost optimization

- [ ] Deploy drift-detector watching traderx spaces
- [ ] Deploy cost-optimizer analyzing traderx units
- [ ] Create combined-view script for TraderX
- [ ] Generate sample drift, show auto-correction

**Success Criteria**:
```bash
# Introduce drift
kubectl scale deployment trade-service --replicas=10 -n traderx-dev

# Drift detector catches it
# Cost optimizer shows impact: +$150/month
# Combined view shows correlation

bin/combined-view trade-service
# Output:
# ğŸ“Š Drift: replicas drifted (3 â†’ 10)
# ğŸ’° Cost: +$150/month
# ğŸ”§ Fix: cub unit update trade-service --patch...
```

---

## Part 7: Expected Outcomes & Success Metrics

### Technical Outcomes

1. **Full ConfigHub Deployment**
   - 8 services deployed via ConfigHub units
   - 3 environments (dev/staging/prod) with push-upgrade
   - Zero kubectl commands (100% ConfigHub)

2. **Worker Automation**
   - Auto-apply on unit changes
   - 10-second deployment cycle
   - Replaces Tilt for all environments

3. **DevOps Apps Integration**
   - Drift detection across all services
   - Cost optimization with AI recommendations
   - Combined insights dashboard

### Demonstration Value

**For FINOS Community:**
- "Here's how to deploy TraderX with ConfigHub instead of kubectl"
- "Zero-downtime upgrades with push-upgrade"
- "Full audit trail of every configuration change"

**For ConfigHub:**
- "Reference fintech app using all 12 canonical patterns"
- "Replaces Tilt with ConfigHub workers"
- "Shows DevOps as Apps value for multi-service systems"

**For Platform Teams:**
- "This is how you manage 8+ microservices without chaos"
- "Cost visibility across entire trading platform"
- "Drift detection prevents configuration sprawl"

### Success Metrics

| Metric | Current (kubectl) | Target (ConfigHub) |
|--------|-------------------|-------------------|
| **Deploy time** | ~10 min (manual) | ~2 min (ordered-apply) |
| **Rollback time** | ~15 min (git revert + redeploy) | ~30 sec (cub unit apply --revision) |
| **Config drift events** | Unknown | 0 (auto-corrected) |
| **Cost visibility** | None | Per-service breakdown |
| **Promotion time** | ~30 min (manual) | ~5 min (push-upgrade) |
| **Audit trail** | Git commits only | Full ConfigHub history |

---

## Appendix A: Quick Start Commands

```bash
# Clone TraderX
git clone https://github.com/finos/traderX
cd traderX

# Add ConfigHub deployment
mkdir -p traderx-confighub/bin
mkdir -p traderx-confighub/confighub/base

# Create base configuration
cd traderx-confighub
./bin/install-base

# Create environment hierarchy
./bin/install-envs

# Deploy to dev
./bin/apply-all dev

# View status
cub unit tree --node=space --filter $(./bin/proj) --space '*'

# Promote to staging
./bin/promote dev staging
./bin/apply-all staging

# Deploy workers for auto-apply
./bin/setup-worker dev
./bin/setup-worker staging
```

---

## Appendix B: Integration with Existing TraderX Repo

**Option 1: Fork and Add ConfigHub**
```bash
git clone https://github.com/finos/traderX
cd traderX
mkdir confighub
# Add ConfigHub deployment alongside existing Kubernetes manifests
```

**Option 2: Separate Repo**
```bash
# Create new repo: traderx-confighub
git init traderx-confighub
# Reference original TraderX as submodule
git submodule add https://github.com/finos/traderX vendor/traderx
# Add ConfigHub-specific deployment
```

**Recommendation**: Option 1 (fork) to submit PR back to FINOS showing ConfigHub as alternative deployment method.

---

## Conclusion

TraderX provides an ideal test case for ConfigHub deployment because:

1. **Complexity**: 8 services demonstrate ConfigHub's strength at scale
2. **Real-world**: Financial services architecture mirrors production systems
3. **Educational**: Already designed for learning, perfect for demonstrating ConfigHub patterns
4. **Community**: FINOS audience would benefit from seeing ConfigHub approach

By deploying TraderX with ConfigHub:
- We validate all 12 canonical patterns on a complex application
- We demonstrate workers as Tilt replacement
- We show DevOps as Apps value for multi-service systems
- We create reusable patterns for fintech deployments

**Next Step**: Implement Phase 1 (Basic ConfigHub Deployment) to prove the concept.
